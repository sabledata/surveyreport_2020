---
title: "Summary of the annual 2020 sablefish (*Anoplopoma fimbria*) trap survey, October 7 - November 21, 2020 "
year: 2021
report_number: nnn
author: |
  Lisa C. Lacko, 
  Schon M. Acheson and
  Brendan M. Connors
author_list: "Lacko, L.C. and Acheson, S.M. and Connors, B.M."
region: Pacific Region
isbn: ""
address: |
     Pacific Biological Station\
     Fisheries and Oceans Canada, 3190 Hammond Bay Road\
     Nanaimo, British Columbia, V9T 6N7, Canada\
phone: "(250) 756-7000"
author_footnote: "Email: Lisa.Lacko@dfo-mpo.gc.ca | telephone: (250) 756-7385"
abstract: |
  This document describes sampling activities and summarizes results from the 2020 British Columbia Sablefish research and assessment survey.  The survey was comprised of stratified random sets (StRS) at five depth-stratified areas.  A portion of the survey (traditional inlet sets) was removed to shorten the survey in response to the COVID-19 pandemic. Biological sampling for sablefish included collection of length, weight, sex, maturity and age structures. Sablefish were randomly sampled from every third trap on all sets, up to  a maximum sample size of 60 sablefish. The tag and release study conducted annually since 1991 was continued in 2020. Sablefish were selected randomly for tag and release from every third trap up to a maximum of 125 fish. 
  
  A total of 48,092 sablefish were caught in 2020, of which 3,691 were used for biological samples and 8,200 were tagged and released.  Catch per unit effort (CPUE) is an important product from this survey as it is used to infer population trends. In most recent years, survey data from stratified random sets showed increasing trends in CPUE in both mean weight and numbers of fish per trap. At the 2020 StRS sites, the stratified mean survey abundance was 35 kg/trap, down -17% from 2019 and -13% from the 2018-2019 average.

  
abstract_other: |
  Le présent document décrit les activités d’échantillonnage réalisées dans le cadre du relevé d’évaluation et de recherche sur la morue charbonnière mené en Colombie-Britannique, et résume les résultats connexes. Ce relevé comprenait des traits ayant fait l’objet d’un échantillonnage aléatoire stratifié qui ont été effectués dans cinq zones stratifiées en fonction de la profondeur. On a éliminé une partie du relevé (traits habituels réalisés dans des bras de mer) pour raccourcir ce dernier en raison de la pandémie de COVID-19. L’échantillonnage biologique de la morue charbonnière comprend la collecte de données sur la longueur, le poids, le sexe, la maturité et les structures selon l’âge. On a échantillonné les morues charbonnières capturées de façon aléatoire à partir du troisième casier de chaque trait, jusqu’à l’atteinte d’une taille d’échantillon maximale de 60 individus. L’étude de marquage et de remise à l’eau menée annuellement depuis 1991 s’est poursuivie en 2020. Dans le cadre de celle-ci, les morues charbonnières ont été choisies de façon aléatoire à partir du troisième casier de chaque trait, jusqu’à l’atteinte d’une quantité maximale de 125 individus. 

  Au total, 48 092 morues charbonnières ont été capturées en 2020. Parmi celles-ci, 3 691 ont été utilisées pour le prélèvement d’échantillons biologiques et 8 200 ont été marquées, puis remises à l’eau. Les captures par unité d’effort (CPUE) représentent des résultats importants du relevé parce qu’on les utilise pour inférer les tendances des populations. Au cours des dernières années, les données de relevé provenant des traits ayant fait l’objet d’un échantillonnage aléatoire stratifié ont montré des tendances à la hausse des CPUE, à la fois pour le poids moyen des prises et le nombre d’individus par casier. Aux sites où ces traits ont été effectués en 2020, l’abondance moyenne stratifiée du relevé était de 35 kg/casier, soit une diminution de 17% par rapport à 2019 et de 13% par rapport à la moyenne de 2018-2019. 

output:
 csasdown::techreport_pdf:
   french: false
type:
  techreport
# ------------
# End of options to set
knit: bookdown::render_book
site: bookdown::bookdown_site
link-citations: true
bibliography: bib/refs.bib
csl: csl/csas.csl
lot: true
lof: true
# Any extra LaTeX code for the header:
# header-includes:
# - \usepackage{tikz}
header-includes: \usepackage{pdflscape}
                 
---

```{r setup, echo=FALSE, cache=FALSE, message=FALSE, results='hide', warning=FALSE}
library(knitr)
if (is_latex_output()) {
  knitr_figs_dir <- "knitr-figs-pdf/"
  knitr_cache_dir <- "knitr-cache-pdf/"
  fig_out_type <- "png"
} else {
  knitr_figs_dir <- "knitr-figs-docx/"
  knitr_cache_dir <- "knitr-cache-docx/"
  fig_out_type <- "png"
}
fig_asp <- 0.618
fig_width <- 9
fig_out_width <- "6in"
fig_dpi <- 180
fig_align <- "center"
fig_pos <- "htb"
opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.path = knitr_figs_dir,
  cache.path = knitr_cache_dir,
  fig.asp = fig_asp,
  fig.width = fig_width,
  out.width = fig_out_width,
  echo = FALSE,
  #  autodep = TRUE,
  #  cache = TRUE,
  cache.comments = FALSE,
  dev = fig_out_type,
  dpi = fig_dpi,
  fig.align = fig_align,
  fig.pos = fig_pos
)
options(xtable.comment = FALSE)
options(kableExtra.latex.load_packages = FALSE)
```

```{r load-libraries, cache=FALSE}
# add other packages here:  
library(csasdown)
message("year = ", rmarkdown::metadata$year)
#browser()

yr       <-  2020
basepath <- 'c:/github/surveyreport_2020/'
path     <- 'c:/github/surveyreport_2020/standaloneData/'

library(RODBC)
library(knitr)
library(magick)
library(excelR)
library(gapminder)
library(ggplot2)
library(dplyr)        # transform and summarize tabular data
library(xtable)       # produces tables
library(kableExtra)   # produces html tables with scrollbars, etc
library(pacman)       # produces numbered tables and figures in order to reference them
 #  if (!require("pacman")) install.packages("pacman")
 #  pacman::p_load(knitr, captioner, bundesligR, stringr)
#library(bookdown)
library(tableHTML)
library(Rmisc)
#library(cowplot)  # for multiple plots

#  ----   G L O B A L --- F U N C T I O N S ---------------------------------

  GetSQLData <- function(strSQL,strDbName) {    # connect to SQL Server
         cnn <- odbcDriverConnect(paste("Driver={SQL Server};Server=DFBCV9TWVASP001;", 
                                         "Database=",
                                          strDbName,";
                                          Trusted_Connection=Yes",
                                          sep=""))
            dat <- sqlQuery(cnn, strSQL)
            odbcClose(cnn)
            return(dat) 
                                            }
  
  panLab <- function( x, y, txt, ... ) { # Allows text to be placed at 0<x<1, 0<y<1)
            usr <- par( "usr" )
            par( usr=c(0,1,0,1) )
            text( x, y, txt, ... )
            par( usr=usr )
            #return( NULL )
            }
  
  cleanf <- function(x){                            # function to remove duplicates
            oldx <- c(FALSE, x[-1]==x[-length(x)])  # is the value equal to the previous
            res <- x
            res[oldx] <- NA
            return(res)
            } 
  
  simpleCap <- function(x) {  # add capital first letter to each word
            s <- strsplit(x, " ")[[1]]
            paste(toupper(substring(s, 1,1)), substring(s, 2),
            sep="", 
            collapse=" ")
            }
  
  firstup <- function(x) {   # add capital first letter to first word
            substr(x, 1, 1) <- toupper(substr(x, 1, 1))
            x
  }
  
  format_cells <- function(df, rows ,cols, value = c("italics", "bold", "strikethrough")){

            # select the correct markup
            map    <- setNames(c("*", "**", "~~"), c("italics", "bold", "strikethrough"))
            markup <- map[value]  
            
            for (r in rows){
                  for(c in cols){
                      df[[c]] <- as.character( df[[c]])  # -- make sure values are not factors
                      df[r, c] <- paste0(markup, df[r, c], markup)  # -- Update formatting
                                }
                           }
                     return(df)
            }
            
  fig_label <- function(text, region="figure", pos="topleft", cex=NULL, ...) {
           
            region <- match.arg(region, c("figure", "plot", "device"))
            pos <- match.arg(pos, c("topleft", "top", "topright", 
                                    "left", "center", "right", 
                                    "bottomleft", "bottom", "bottomright"))
           
            if(region %in% c("figure", "device")) {
              ds <- dev.size("in")
              # xy coordinates of device corners in user coordinates
              x <- grconvertX(c(0, ds[1]), from="in", to="user")
              y <- grconvertY(c(0, ds[2]), from="in", to="user")
           
              # fragment of the device we use to plot
              if(region == "figure") {
                # account for the fragment of the device that 
                # the figure is using
                fig <- par("fig")
                dx <- (x[2] - x[1])
                dy <- (y[2] - y[1])
                x <- x[1] + dx * fig[1:2]
                y <- y[1] + dy * fig[3:4]
              } 
            }
           
            # much simpler if in plotting region
            if(region == "plot") {
              u <- par("usr")
              x <- u[1:2]
              y <- u[3:4]
            }
           
            sw <- strwidth(text, cex=cex) * 60/100
            sh <- strheight(text, cex=cex) * 60/100
           
            x1 <- switch(pos,
              topleft     =x[1] + sw, 
              left        =x[1] + sw,
              bottomleft  =x[1] + sw,
              top         =(x[1] + x[2])/2,
              center      =(x[1] + x[2])/2,
              bottom      =(x[1] + x[2])/2,
              topright    =x[2] - sw,
              right       =x[2] - sw,
              bottomright =x[2] - sw)
           
            y1 <- switch(pos,
              topleft     =y[2] - sh,
              top         =y[2] - sh,
              topright    =y[2] - sh,
              left        =(y[1] + y[2])/2,
              center      =(y[1] + y[2])/2,
              right       =(y[1] + y[2])/2,
              bottomleft  =y[1] + sh,
              bottom      =y[1] + sh,
              bottomright =y[1] + sh)
           
            old.par <- par(xpd=NA)
            on.exit(par(old.par))
           
            text(x1, y1, text, cex=cex, ...)
            return(invisible(c(x,y)))
            }
  
    inline_hook <- function(x) {  # -- for inline text where numbers are larger 
      if (is.numeric(x)) {
            format(x, digits = 2)
                         } else x
      }
    knitr::knit_hooks$set(inline = inline_hook)
  
  

```


```{r SurveyDetails, echo=FALSE}  
   # -- INTRODUCTION DETAILS --

   report      <-  'exec Report_CreateTables'
   #rep.data    <-  GetSQLData(report,"Sablefish")
   details <- "select * from GFSH_"
   details     <- paste("select VESSEL_NAME as Vessel, CAPTAIN, ",
                        "left(CONVERT(varchar, START_DATE, 100), 7) + ' - ' ",
                        "+ left(CONVERT(varchar, END_DATE, 100), 7) AS [Trip Dates], ",
                        "COUNT([SET]) AS [Count of Sets], ",
                        "DATEDIFF(DAY, START_DATE, END_DATE) + 1 as days, ",
                        "DATEDIFF(DAY, '10/07/2020', '10/22/2020') + 1 as leg_one, ", 
                        "DATEDIFF(DAY, '10/23/2020', '11/21/2020')  as leg_two, ",
                        "START_DATE, END_DATE ",   #taken from survey notes
                        "from  dbo.GFBIO_RESEARCH_TRIPS ",
                        "where year IN( ", yr ,") ", 
                        "group by ",
                        "VESSEL_NAME, CAPTAIN,  ",
                        "left(CONVERT(varchar, START_DATE, 100),7) + ' - ' + ",
                        "left(CONVERT(varchar, END_DATE, 100),7), ",
                        "DATEDIFF(DAY, START_DATE, END_DATE), START_DATE, END_DATE",
                         sep="")
   #sd     <- GetSQLData(details,"Sablefish")  # -- survey details
   #write.table( sd, file = paste(path,"index01.csv",sep=''),row.names=FALSE, na="",col.names=TRUE,  sep=",")
   sd     <- read.csv(paste(path,'index01.csv',sep=''), header=T)
   
   boat        <- simpleCap(tolower(sd[1,1]))      # -- vessel name 
   captain     <- "Albert (Deacon) Melnychuk"      # -- captain name -- override for 2020
   dates       <- sd[1,3]                          # -- survey start and end dates 
   setcnt      <- sd[1,4]                          # -- survey set count 
   days        <- sd[1,5]                          # -- days survey total to match paper docs
   legone      <- sd[1,6]    
   legtwo      <- sd[1,7]   

   avgC        <- paste("select round(AVG(TOTAL), 0) AS YrAvg ",
                        "from   dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2 ",
                        "where  (year <= ", yr, ") and (year >= ",yr - 9,")", sep="")
   #avgTen      <- GetSQLData(avgC,"Sablefish")    # -- average catch last 10 years 
   #write.table(avgTen, file = paste(path,"index02.csv",sep=''),row.names=FALSE, na="",col.names=TRUE,  sep=",")
   avgTen      <- read.csv(paste(path,'index02.csv', sep=''),header=T)
   
   tp          <- paste("select round(TRAP / TOTAL * 100, 0) AS TrapPer ",
                        "from dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2 ",  
                        "where  (year = ", yr, ")  group by round(TRAP / TOTAL * 100, 0), TOTAL", sep="")
   #trapP       <- GetSQLData(tp,"Sablefish")        # -- trap gear catch ratio
   #write.table(trapP, file = paste(path,"index03.csv",sep=''),row.names=FALSE, na="",col.names=TRUE,  sep=",")   
   trapP      <- read.csv(paste(path,'index03.csv', sep=''),header=T)
   
   lp          <- paste( "select  round(LONGLINE / TOTAL * 100, 0) AS LonglinePer from ",  
                         "dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2  ",
                         "where  (year = ", yr, ") group by round(LONGLINE / TOTAL * 100, 0), TOTAL", sep="")
   #LonglineP   <- GetSQLData(lp,"Sablefish")        # -- longline gear catch ratio
   #write.table(LonglineP, file = paste(path,"index04.csv",sep=''),row.names=FALSE, na="",col.names=TRUE,  sep=",")    
   LonglineP   <- read.csv(paste(path,'index04.csv', sep=''), header=T)

   # -- F I G U R E   C A P T I O N S  function ------------------------------------------------
   figure_nums <-  captioner::captioner(prefix = "Figure")
   fg.ref      <-  function(x) {    # another method on how to number figures
                                     stringr::str_extract(figure_nums(x), "[^.]*")}

```

